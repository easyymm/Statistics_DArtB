
# 통계학 4주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_4th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

4주차는 `2부. 데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_4th_TIL

### 2부. 데이터 분석 준비하기
### 10. 데이터 탐색과 시각화



## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | 🍽️      | 
|6주차| 3부 p.300~356  | 🍽️      | 
|7주차| 3부 p.357~615  | 🍽️      | 

<!-- 여기까진 그대로 둬 주세요-->

# 10. 데이터 탐색과 시각화

```
✅ 학습 목표 :
* EDA의 목적을 설명할 수 있다.
* 주어진 데이터셋에서 이상치, 누락값, 분포 등을 식별하고 EDA 결과를 바탕으로 데이터셋의 특징을 해석할 수 있다.
* 공분산과 상관계수를 활용하여 두 변수 간의 관계를 해석할 수 있다.
* 적절한 시각화 기법을 선택하여 데이터의 특성을 효과적으로 전달할 수 있다.
```
<!-- 새롭게 배운 내용을 자유롭게 정리해주세요.-->

## 📍 10.1. 탐색적 데이터 분석

▪️ EDA와 데이터 시각화: EDA 단계에서 데이터 파악을 좀 더 효율적으로 하기 위해 시각화를 하기도 하지만, 데이터 시각화의 궁극적 목적은 분석 결과를 커뮤니케이션하기 위함이다.

▪️ EDA의 주요 목적
  
🔹 데이터 형태와 척도가 분석에 알맞게 되어있는지 확인(sanity checking)  
🔹 데이터의 평균, 분산, 분포, 패턴 등의 확인을 통해 데이터 특성 파악  
🔹 데이터의 결측값이나 이상치 파악 및 보완  
🔹 변수 간 관계성 파악  
🔹 분석 목적과 방향성 점검 및 보정

### ✏️ 10.1.1. 엑셀을 활용한 EDA
▪️ 단순 임의추출로 샘플 1,000개를 살펴보는 방법. 데이터를 대략적으로 파악하기에 용이함.

▪️ 적은 데이터를 다룰 때에는 엑셀이 가장 사용자 친화적이고 효율적이다.

### ✏️ 10.1.2. 탐색적 데이터 분석 실습
▪️ 기초 통계량 확인
```python
# 데이터 샘플 확인
df.head()

# 각 컬럼 속성 및 결측치 확인
df.info()

# 각 컬럼 통계치 확인
df.describe()

# 각 컬럼 왜도 확인
df.skew()

# 각 컬럼 첨도 확인
df.kurtosis()
```

▪️ 시각화
```python
# 특정 변수 분포 시각화
sns.distplot(df['lead_time'])

# 호텔 구분에 따른 lead_time 분포 차이 시각화
sns.violinplot(x="hotel", y="lead_time", data=df, inner=None, color=".8")
sns.stripplot(x="hotel", y="lead_time", data=df, size=1)
```

## 📍 10.2. 공분산과 상관성 분석
▪️ 타깃변수와 입력변수의 관계는 물론, 입력변수들 간의 관계도 살펴보아야 한다.

### ✏️ 10.2.1. 공분산
▪️ 두개의 확률 변수의 선형 관계를 나타내는 값. 두 확률 변수의 흩어진 정도.

▪️ 양/음/무의 상관관계를 알 수 있다.

▪️ 각 변수 간 다른 척도기준이 그대로 반영되어 공분산 값이 지니는 크기가 상관성의 정도를 나타내지 못한다. 즉, 공분산 값 간 비교를 할 수 없다.

▪️ 공분산을 변수 각각의 표준편차 값으로 나누는 정규화를 하여 상관성을 비교하기도 하나, 이 역시 절대적인 기준이 되지는 못한다.

### ✏️ 10.2.2. 상관계수
▪️ 피어슨 상관계수: 변수 X_1과 X_2가 함께 변하는 정도(공분산)를 X_1과 X_2가 변하는 전체 정도로 나눠준 것. -1 ≤ R ≤ 1.

▪️ 일반적으로 절댓값이 0.7 이상이면 상관관계가 매우 높다, 0.4 이상이면 어느 정도 상관관계가 있다고 해석.

▪️ 단, 산점도의 기울기와 상관계수는 관련이 없다. 

▪️ 상관분석은 두 변수의 선형관계만을 측정하므로, 상관관계가 낮더라도 다른 통계적 관계나 패턴이 있을 수 있다. 따라서 변수 간 관계를 평가할 때에는 상관계수뿐만 아니라 다양한 통계적 방법과 시각화 기법을 함께 사용해야 한다.

▪️ 이상치에 의해 상관도가 크게 달라질 수 있으므로, 산점도 그래프를 함께 확인해보면 좋다.

▪️ 변수 척도에 따른 상관분석 방법
| 종류                                      | 척도                                 |
|-----------------------------------------|--------------------------------------|
| Pearson correlation coefficient         | 간격/비율 – 간격/비율                |
| Spearman's rank correlation coefficient | 서열 – 서열                          |
| Point–biserial correlation coefficient  | 간격/비율 – 명목(2분 변수)           |
| Phi coefficient                         | 명목(2분 변수) – 명목(2분 변수)      |
| Cramer's coefficient                    | 명목 – 명목 (2 × 2 이상)             |


### ✏️ 10.2. 공분산과 상관성 분석 실습
▪️ 공분산/상관성 분석 코드
```python
# 산점도 행렬 시각화
sns.set(font_scale=1.1) ## 폰트 크기 설정
sns.set_style('ticks') ## 축 눈금 설정
sns.pairplot(df,
             diag_kind='kde' # 상관계수가 1이면 분포로 표시
            )
plt.show()

# 공분산 확인
df.cov()

# 피어슨 상관계수 확인
df.corr(method='pearson')

# 히트맵 시각화
sns.heatmap(df.corr(), cmap='viridis')

# clustermap 히트맵 시각화
sns.clustermap(df.corr(), 
               annot = True,      
               cmap = 'RdYlBu_r',  
               vmin = -1, vmax = 1,
              )


### 가독성 높이기: 중복 영역 제거 히트맵 ###

# 매트릭스의 우측 상단을 모두 True인 1로, 하단을 False인 0으로 변환.
np.triu(np.ones_like(df.corr()))

# True/False mask 배열로 변환.
mask = np.triu(np.ones_like(df.corr(), dtype=np.bool))

#  히트맵 그래프 생성
fig, ax = plt.subplots(figsize=(15, 10))
sns.heatmap(df.corr(), 
            mask=mask, 
            vmin=-1, 
            vmax = 1, 
            annot=True, 
            cmap="RdYlBu_r", 
            cbar = True)
ax.set_title('Wine Quality Correlation', pad = 15)
```

## 📍 10.3. 시간 시각화

▪️ 시계열 데이터는 선 그래프(연속형)와 막대그래프(분절형)으로 시각화한다.

▪️ 흔히 **선 그래프** 사용. 시간 간격의 밀도가 높을 때 사용한다. 다만 데이터 양이 많거나 변동이 심하면, **추세선**을 삽입하여 전체적인 경향이나 패턴을 쉽게 파악할 수 있다.

▪️ **이동평균 방법**: 데이터의 연속적 그룹의 평균. 추세선을 그리는 가장 일반적인 방법.

▪️ **분절형 시간 시각화**: 막대그래프, 누적 막대그래프, 점 그래프 등으로 표현. 시간의 밀도가 낮은 경우 활용하기에 좋음.  
🔹 누적 막대그래프: 한 시점에 2개 이상의 세부 항목이 존재할 때 사용. 절대적 비율을 비교할 수 있도록 표현할 수도 있다.

### ✏️ 10.3.1. 시간 시각화 실습
▪️ 날짜 가공
```python
# 날짜 가공: datetime 패키지
import datetime

# date 컬럼 날짜형식 변환
df['Date2']= pd.to_datetime(df['Order Date'], infer_datetime_format=True) 

# 날짜 오름차순 정렬
df = df.sort_values(by='Date2')

# 연도 컬럼 생성
df['Year'] = df['Date2'].dt.year

## 선 그래프 용 데이터셋 생성
# 2018년 데이터만 필터링
df_line=df[df.Year == 2018]

# 2018년 일 별 매출액 가공
df_line = df_line.groupby('Date2')['Sales'].sum().reset_index()
```
▪️ 시각화
```python
# 30일 이동평균 생성
df_line['Month'] = df_line['Sales'].rolling(window=30).mean()

# 선 그래프 시각화
ax = df_line.plot(x='Date2', y='Sales',linewidth = "0.5")
df_line.plot(x='Date2', y='Month', color='#FF7F50', linewidth = "1", ax=ax)

# 연도 별 판매량 데이터 가공
df_bar_1 = df.groupby('Year')['Sales'].sum().reset_index()

# 연도 별 매출액 막대 그래프 시각화
ax = df_bar_1.plot.bar(x='Year', y='Sales', rot=90, figsize=(10,5))

#연도별, 고객 세그먼트 별 매출액 데이터 가공
df_bar_2 = df.groupby(['Year', 'Segment'])['Sales'].sum().reset_index()

# 고객 세그먼트를 컬럼으로 피벗
df_bar_2_pv = df_bar_2.pivot(index='Year', 
                             columns='Segment', 
                             values='Sales').reset_index()

# 연도 별 고객 세그먼트 별 매출액 누적 막대 그래프 시각화
df_bar_2_pv.plot.bar(x='Year', stacked=True, figsize=(10,7))
```

## 📍 10.4. 비교 시각화

▪️ 그룹별 요소가 많아질 때, **히트맵 차트**로 효과적 시각화 가능.  
🔹 각 그룹이 어떤 요소에서 높은/낮은 값을 가지는지를 쉽게 파악할 수 있고, 요소 간 관계 파악이 가능.  
🔹 다른 방법들에 비해 그리는 것이 까다로우므로 현재 가지고 있는 데이터의 구조와 확인하고자 하는 목적을 정확히 파악한 다음 차트를 그려야 하며, 적정 수준으로 데이터를 정제하여 적당한 수의 변수를 시각화하여야 한다.


![Image](https://github.com/user-attachments/assets/6b3ad303-3307-4fb9-a3e0-c7d9a1b6d11c)

▪️ **방사형 차트**: 하나의 차트에 하나의 그룹을 시각화하거나, 모든 그룹을 한번에 시각화할 수 있다.

![Image](https://github.com/user-attachments/assets/4c203eb6-160f-4602-b392-8bdae7a8896d)

▪️ **평행 좌표그래프**를 통한 그룹별 요소 비교 시각화도 가능하다. 변수별 값을 정규화하여, 0~100% 사이로 변환하면 각 그룹의 요소별 차이 수준을 효과적으로 파악할 수 있으며, 집단적 경향성 표현에 용이하다.

![Image](https://github.com/user-attachments/assets/60dd8b41-a331-4b78-869e-e7c196fe969d)


### ✏️ 10.4.1. 비교 시각화 실습

```python
# 선그래프, 히트맵, 방사형 차트, 평행 좌표 그래프 시각화에 필요한 패키지
from math import pi
from pandas.plotting import parallel_coordinates

# 히트맵 시각화 V1을 위한 데이터 전처리

# 5개 팀만 필터링
df1 = df[df['Tm'].isin(['ATL','BOS','BRK','CHI','CHO'])]

# 6개 컬럼만 필터링 
df1 = df1[['Tm', 'ORB%','TRB%','AST%','BLK%','USG%']]

#  팀 별 요소 평균 전처리
df1 = df1.groupby('Tm').mean()
df1.head()

# 히트맵 시각화 V1

fig = plt.figure(figsize=(8,8))
fig.set_facecolor('white')
plt.pcolor(df1.values)

# x축 컬럼 설정
plt.xticks(range(len(df1.columns)),df1.columns) 
# y축 컬럼 설정
plt.yticks(range(len(df1.index)), df1.index)
# x축 레이블 설정
plt.xlabel('Value', fontsize=14)
# y축 레이블 설정
plt.ylabel('Team', fontsize=14) 
plt.colorbar()
plt.show()

# 히트맵 시각화 V2를 위한 데이터 전처리

# 5개 팀만 필터링
df2 = df[df['Tm'].isin(['ATL','BOS','BRK','CHI','CHO'])]

# 팀명, 연령, 참여 게임 수 컬럼만 필터링
df2 = df2[['Tm','Age','G']]

# 팀 - 연령 기준 평균으로 전처리
df2 = df2.groupby(['Tm','Age']).mean().reset_index()

# 테이블 피벗
df2 = df2.pivot(index='Tm', columns='Age', values='G')
df2.head()

# 히트맵 시각화 V2

fig = plt.figure(figsize=(8,8))
fig.set_facecolor('white')
 
plt.pcolor(df2.values)
# x축 컬럼 설정
plt.xticks(range(len(df2.columns)),df2.columns)
# y축 컬럼 설정
plt.yticks(range(len(df2.index)), df2.index)
# x축 레이블 설정
plt.xlabel('Age', fontsize=14)
# y축 레이블 설정
plt.ylabel('Team', fontsize=14) 
plt.colorbar()
plt.show()

# 방사형 차트를 위한 인덱스 초기화
df3 = df1.reset_index()

# 방사형 차트 - 하나씩 시각화

labels = df3.columns[1:]
num_labels = len(labels)

# 등분점 생성    
angles = [x/float(num_labels)*(2*pi) for x in range(num_labels)] 
angles += angles[:1] # 시작점 생성
    
my_palette = plt.cm.get_cmap("Set2", len(df3.index))
 
fig = plt.figure(figsize=(15,20))
fig.set_facecolor('white')
 
for i, row in df3.iterrows():
    color = my_palette(i)
    data = df3.iloc[i].drop('Tm').tolist()
    data += data[:1]
    
    ax = plt.subplot(3,2,i+1, polar=True)
    # 시작점 설정
    ax.set_theta_offset(pi / 2)
    # 시계방향 설정
    ax.set_theta_direction(-1) 
    
    # 각도 축 눈금 생성
    plt.xticks(angles[:-1], labels, fontsize=13)
    # 각 축과 눈금 사이 여백생성
    ax.tick_params(axis='x', which='major', pad=15)
    # 반지름 축 눈금 라벨 각도 0으로 설정
    ax.set_rlabel_position(0)
    # 반지름 축 눈금 설정
    plt.yticks([0,5,10,15,20],['0','5','10','15','20'], fontsize=10) 
    plt.ylim(0,20)
    
    # 방사형 차트 출력
    ax.plot(angles, data, color=color, linewidth=2, linestyle='solid')
    # 도형 안쪽 색상 설정
    ax.fill(angles, data, color=color, alpha=0.4) 
    # 각 차트의 제목 생성
    plt.title(row.Tm, size=20, color=color,x=-0.2, y=1.2, ha='left') 
# 차트 간 간격 설정 
plt.tight_layout(pad=3) 
plt.show()

# 방사형 차트 - 한번에 시각화

labels = df3.columns[1:]
num_labels = len(labels)

# 등분점 생성
angles = [x/float(num_labels)*(2*pi) for x in range(num_labels)]
# 시작점 생성
angles += angles[:1] 
    
my_palette = plt.cm.get_cmap("Set2", len(df3.index))
 
fig = plt.figure(figsize=(8,8))
fig.set_facecolor('white')
ax = fig.add_subplot(polar=True)
for i, row in df3.iterrows():
    color = my_palette(i)
    data = df3.iloc[i].drop('Tm').tolist()
    data += data[:1]
    
    # 시작점
    ax.set_theta_offset(pi / 2) 
    # 시계방향 설정
    ax.set_theta_direction(-1) 
    
    # 각도 축 눈금 생성
    plt.xticks(angles[:-1], labels, fontsize=13)
    # 각 축과 눈금 사이 여백생성
    ax.tick_params(axis='x', which='major', pad=15) 
    # 반지름 축 눈금 라벨 각도 0으로 설정 
    ax.set_rlabel_position(0) 
    # 반지름 축 눈금 설정
    plt.yticks([0,5,10,15,20],['0','5','10','15','20'], fontsize=10) 
    plt.ylim(0,20)
    
    # 방사형 차트 출력
    ax.plot(angles, data, color=color, linewidth=2, linestyle='solid', label=row.Tm) 
    # 도형 안쪽 색상 설정
    ax.fill(angles, data, color=color, alpha=0.4) 
    
plt.legend(loc=(0.9,0.9))
plt.show()

# 팀 기준 평행 좌표 그래프 생성

fig,axes = plt.subplots()
plt.figure(figsize=(16,8)) # 그래프 크기 조정
parallel_coordinates(df3,'Tm',ax=axes, colormap='winter',linewidth = "0.5")
```


## 📍 10.5. 분포 시각화

▪️ 양적 척도(연속형): 막대그래프, 선그래프, 히스토그램 

▪️ 질적 척도(명목형): 파이차트, 도넛차트, 트래맵 차트, 와플 차트

- 와플 차트  
![Image](https://github.com/user-attachments/assets/ff087d85-0fe3-43c6-90b7-6b09f5f8fc19)

### ✏️ 10.5.1. 분포 시각화 실습
```python
# 필요한 패키지
!pip install plotly
!pip install pywaffle
import plotly.express as px
from pywaffle import Waffle

# 기본 히스토그램 시각화

#  신장 컬럼만 필터링
df1 = df[['height_cm']]

# 10cm 단위로 히스토그램 시각화
plt.hist(df1, bins=10, label='bins=10')
plt.legend()
plt.show()

# 남성 여성 히스토그램 시각화

#  남성 여성 별도 데이터셋 생성
df1_1 = df[df['sex'].isin(['man'])]
df1_1 = df1_1[['height_cm']]
df1_2 = df[df['sex'].isin(['woman'])]
df1_2 = df1_2[['height_cm']]

# 10cm 단위로 남성, 여성 신장 히스토그램 시각화
plt.hist(df1_1, color = 'green', alpha = 0.2, bins = 10, label = 'MAN', density = True)
plt.hist(df1_2, color = 'red', alpha = 0.2, bins = 10, label = 'WOMAN', density = True)
plt.legend()
plt.show()

# 파이차트, 도넛차트 시각화를 위한 데이터 전처리

df2 = df[['country','height_cm']]
# 키 175 이상만 추출
df2=df2[df.height_cm >= 175]
df2 = df2.groupby('country').count().reset_index()

df2.head(10)

# 파이차트 시각화

fig = plt.figure(figsize=(8,8)) ## 캔버스 생성
fig.set_facecolor('white') ## 캔버스 배경색 설정
ax = fig.add_subplot() # 프레임 생성

# 파이차트 출력
ax.pie(df2.height_cm, 
       labels=df2.country, # 라벨 출력
       startangle=0, # 시작점 degree 설정
       counterclock=False, # 시계 방향
       autopct=lambda p : '{:.1f}%'.format(p) # 퍼센자릿수 설정
       )

plt.legend() # 범례 표시
plt.show()

# 도넛차트 시각화

# 차트 형태 옵션 설정
wedgeprops={'width': 0.7, 'edgecolor': 'w', 'linewidth': 5}

plt.pie(df2.height_cm, labels=df2.country, autopct='%.1f%%', 
        startangle=90, counterclock=False, wedgeprops=wedgeprops)
plt.show()

# 트리맵 차트용 데이터셋 전처리

df3 = df[['country', 'sex', 'height_cm']]
df3=df3[df.height_cm >= 175]
# 국가, 성별 단위 신장 175cm 이상 카운팅
df3 = df3.groupby(['country','sex']).count().reset_index()

df3.head(10)

# 트리맵 차트 시각화

fig = px.treemap(df3,
                 path=['sex','country'],
                 values='height_cm',
                 color='height_cm',
                 color_continuous_scale='viridis')

fig.show()

# 와플차트 시각화

fig = plt.figure(
    FigureClass=Waffle,
    plots={
        111: {
            'values': df2['height_cm'],
            'labels': ["{0} ({1})".format(n, v) for n, v in df2['country'].items()],
            'legend': {'loc': 'upper left', 'bbox_to_anchor': (1.05, 1), 'fontsize': 8},
            'title': {'label': 'Waffle chart test', 'loc': 'left'}
        }
    },
    rows=10,
    figsize=(10, 10) 
)


```

## 📍 10.6. 관계 시각화

▪️ 산점도: 시각화의 효율을 위해, 극단치를 제거하고 그리는 것이 좋다. 또한 각 점에 투명도를 주어 점들의 밀도를 표현할 수 있다.

▪️ 버블 차트: 세 가지 요소의 상관관계 표현 가능. 원의 면적을 함께 보므로 관측치가 많이 않아야 한다(100개 이하). 버블차트를 해석할 때, 원의 지름이 아닌 면적으로 크기를 판단해야 하므로 주의.

![Image](https://github.com/user-attachments/assets/43dc6759-c086-4af4-8e3d-caf9d9db7282)

▪️ 

🔹 
### ✏️ 10.6.1. 관계 시각화 실습
```python
# 기본 산점도 시각화

plt.scatter(df['R&D Spend'], df['Profit'], s = 50, alpha = 0.4)
plt.show()

# 산점도에 회귀선 추가
ax = sns.lmplot(x='R&D Spend', y='Profit', data= df)

# 네 가지 요소의 정보를 포함한 산점도 시각화

plt.scatter(df['R&D Spend'], df['Profit'], s=df['Marketing Spend']*0.001, 
            c=df['Administration'], alpha=0.5, cmap='Spectral')
plt.colorbar()
plt.show()
```

## 📍 10.7. 공간 시각화

▪️ 지도 위에 데이터를 매핑하여 시각적으로 표현할 수 있다. 확대, 위치 이동 등 인터랙티브한 활용이 가능하므로, 거시적에서 미시적으로 진행되는 분석 방향과 같이 스토리라인을 잡고 시각화를 적용하는 것이 좋다.

![Image](https://github.com/user-attachments/assets/876cf57d-dc8a-403a-8919-6babb02630aa)

🔹 **도트맵**: 동일한 크기의 작은 점을 찍어 데이터 분포나 패턴 표현. 정확한 값 전달에는 적합하지 않음.  
🔹 **버블맵**: 데이터 값이 원의 크기로 표현됨.   
🔹 **코로플레스맵**: 단계 구분도. 데이터 값 크기에 따라 색상의 음영을 달리하여 해당 지역에 대한 값 시각화. 여러 색상 혼합 가능, 투명도, 명도, 채도 등을 다양하게 표현 가능. 정확한 수치 인지 밎 비교는 어려움. 큰 지역이 강조되는 인상을 줄 수 있어 유의해야 함.  
🔹 **커넥션맵/링크맵**: 지도에 찍힌 점들을 곡선 또는 직선으로 연결하여 지리적 관계 표현. 연속적 연결으로 지도에 경로를 표현할 수도 있음. 일반적으로 연결선의 분포와 집중도를 통해 지리적 관계의 패턴 파악을 위해 사용. 지역 간 무역 관계, 항공 경로, 통신 정보 흐름 등 표현에 사용.  
🔹 그 밖에도 플로우맵(시작점-도착점 표현), 카토그램(각 지역의 면적을 데이터 값에 비례하도록 변형시켜 시각화), 지도 위에 바차트, 파이차트 등 표현 가능.


### ✏️ 10.7.1. 공간 시각화 실습
- 서울 스타벅스 지점
```python
# 필요한 패키지 설치
!pip install folium
import folium
from folium import Marker
from folium import plugins
from folium import GeoJson
import plotly.graph_objects as go

# 서울 스타벅스 지점 데이터 불러오기
# https://www.kaggle.com/datasets/sewonghwang/starbucks-seoul
df=pd.read_csv("datasets/Starbucks_Seoul.csv")

# 지역 구분을 위한 json 파일 불러오기
geo="datasets/Seoul_Gu.json" 

# 기본 지도 시각화 (서울의 위도, 경도 입력)

m = folium.Map(location=[37.541, 126.986], zoom_start=12)

# 지도 형태 변경
m = folium.Map(location=[37.541, 126.986], tiles='Stamen Toner', zoom_start=12)

# 원하는 좌표에 반경(radius) 표시 (남산)
folium.CircleMarker([37.5538, 126.9810],radius=50, 
                    popup='Laurelhurst Park', color='#3246cc', 
                    fill_color='#3246cc').add_to(m)

# 원하는 좌표에 포인트 표시 (남산)
folium.Marker([37.5538, 126.9810], popup='The Waterfront').add_to(m)

# 서울 지도에 스타벅스 지점 수 시각화

m = folium.Map([37.541, 126.986], zoom_start=12 ,width="%100", height="%100")
locations = list(zip(df.latitude, df.longitude))
cluster = plugins.MarkerCluster(locations=locations,                     
               popups=df["name"].tolist())  
m.add_child(cluster)

# 서울 지도에 스타벅스 지점수 도드맵 시각화

m = folium.Map(location=[37.541, 126.986], zoom_start=12, width="%100", height="%100")
locations = list(zip(df.latitude, df.longitude))
for i in range(len(locations)):
    folium.CircleMarker(location=locations[i],radius=1).add_to(m)


Make this Notebook Trusted to load map: File -> Trust Notebook
# 서울 구 별 스타벅스 지점 수 집계 및 중심점 산출
df_m = df.groupby('gu_name').agg({'latitude':'mean',
                                  'longitude':'mean',
                                  'name':'count'}).reset_index()
                                
# 서울 구 별 스타벅스 지점 수 버블맵 시각화

# 기본 지도 생성
m = folium.Map(location=[37.541, 126.986], tiles='Cartodb Positron', 
               zoom_start=11, width="%100", 
               height="%100")

# 구별 구분선, 색상 설정
folium.Choropleth(
    geo_data=geo, # 앞에서 불러온 json 파일 적용
    fill_color="gray"
    ).add_to(m)

# 버블맵 삽입
locations = list(zip(df_m.latitude, df_m.longitude))
for i in range(len(locations)):
    row = df_m.iloc[i]
    folium.CircleMarker(location=locations[i],
                        radius= float(row.name/2), # 버블 크기 설정
                        fill_color="blue"
                       ).add_to(m)

# radius에 카운팅을 넣어줌
# 만약 원이 커서 겹치면 float(row.name/1)의 분모값을 조정                                
```

- 미국 주별 실업률
```python
# 미국 실업률 정보의 코로플레스맵 시각화를 위한 데이터, json 불러오기
# https://www.kaggle.com/datasets/sewonghwang/us-unemployment
df2 =pd.read_csv("datasets/us_states_unemployment.csv")

# 주 별 경계 json 파일 불러오기
us_geo = 'datasets/folium_us-states.json'

# 미국 주별 실업률 코로플레스맵 시각화

# 미국 지도 시각화
m = folium.Map(location=[40,-98], zoom_start=3, tiles="Cartodb Positron")

# 지도에 주 경계선, 실업률 데이터 연동
m.choropleth(geo_data = us_geo, # json 데이터
               data = df2, # 실업률 데이터
               columns = ['State','Unemployment'], # 연동할 컬럼 설정
               key_on = 'feature.id', # json과 실업률 데이터를 연결할 키값 설정
               fill_color='YlGn',
               legend_name='실업률')
```

- 서울과 각국 수도 간 커넥션맵
```python
# 서울과 각국의 수도 간의 커넥션맵 시각화

# 서울과 도쿄, 워싱턴, 마닐라, 파리, 모스크바 위경도 입력
source_to_dest = zip([37.541,37.541,37.541,37.541,37.541], 
                     [35.6804, 38.9072, 14.5995, 48.8566,55.7558],
                     [126.986,126.986,126.986,126.986,126.986], 
                     [139.7690, -77.0369, 120.9842, 2.3522,37.6173])

fig = go.Figure()

## for 문을 활용하여 위경도 입력
for a, b, c, d in source_to_dest:
    fig.add_trace(go.Scattergeo(
                        lat = [a, b],
                        lon = [c, d],
                        mode = 'lines',
                        line = dict(width = 1, color="red"),
                        opacity = 0.5 # 선 투명도
                        ))

fig.update_layout(
                margin={"t":0,"b":0,"l":0, "r":0, "pad":0},
                showlegend=False,
                geo = dict(
                showcountries=True) # 국가 경계선
                )

fig.show()
```

## 📍 10.8. 박스 플롯

▪️ 하나의 그림으로 양적 척도 데이터의 분포 및 편향성, 평균과 중앙값 등 다양한 수치를 보기 쉽게 정리해줌. 특히 두 변수의 값을 비교할 때 효과적임.

▪️ 박스플롯 수치 종류

🔹 최솟값  
🔹 제1사분위  
🔹 제2사분위  
🔹 제3사분위  
🔹 최댓값  

▪️ 박스플롯은 데이터의 분포를 정형화시켜 정보를 축약한 것. 해석 시에는 항상 데이터 분포도를 함께 떠올리는 습관이 필요하다.


### ✏️ 10.8.1. 박스 플롯 실습
```python
# Profit 변수로 기본 가로 세로 박스 플롯 시각화

# 세로 박스 플롯
plt.figure(figsize = (8, 6))
sns.boxplot(y = 'Profit', data = df)
plt.show()

# 가로 박스 플롯
plt.figure(figsize = (8, 2))
sns.boxplot(x = 'Profit', data = df)
plt.show()

# State 구분에 따른 Profit 박스 플롯 시각화

plt.figure(figsize=(8,5))
sns.boxplot(x="State", y="Profit", data=df)
plt.show()

# 평균, 데이터 포인트 포함한 박스 플롯 시각화
sns.boxplot(x="State", y="Profit", 
            showmeans=True, 
            boxprops={'facecolor':'None'}, 
            data=df)

sns.stripplot(x='State', y='Profit', 
              data=df, 
              jitter=True, 
              marker='o', 
              alpha=0.5,
              color='black')

plt.show()
```

---

# 확인 문제

## 문제 1.
> **🧚 공분산과 상관계수의 차이점에 대해 간단히 설명하세요.**

```
공분산은 두 확률 변수가 얼마나 상관이 있는지를 나타내며, 상관관계의 크기를 비교할 수는 없다.
공분산을 표준화시켜 객관성을 확보한 것이 상관계수이다. -1과 1 사이 값으로 나타낸다.
```

## 문제 2.
> **🧚 다음 데이터 분석 목표에 적합한 시각화 방법을 보기에서 모두 골라 연결해주세요.**

> 보기: 산점도, 선그래프, 막대그래프, 히스토그램, 박스플롯

(a) 변수의 분포 확인   
(b) 두 변수 간의 관계 확인   
(c) 집단별 평균 비교   
(d) 시계열 데이터 분석

<!--중복 가능-->

```
(a) 히스토그램, 박스플롯
(b) 산점도
(c) 박스플롯
(d) 선 그래프, 막대그래프
```


### 🎉 수고하셨습니다.