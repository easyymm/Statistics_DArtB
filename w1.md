# 통계학 1주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_1st_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

1주차는 `1부. 데이터 기초체력 기르기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_1st_TIL

### 1부. 데이터 기초체력 기르기
### 01. 통계학 이해하기
### 02. 모집단과 표본추출
### 03. 변수와 척도
### 04. 데이터의 기술 통계적 측정
### 05. 확률과 확률변수

## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | 🍽️      | 
|3주차| 2부 p.82~120   | 🍽️      | 
|4주차| 2부 p.121~202  | 🍽️      | 
|5주차| 2부 p.203~254  | 🍽️      | 
|6주차| 3부 p.300~356  | 🍽️      | 
|7주차| 3부 p.357~615  | 🍽️      | 

<!-- 여기까진 그대로 둬 주세요-->

# 01. 통계학 이해하기

```
✅ 학습 목표 :
* 통계학의 필요성에 대해 인식한다.
* 기술통계와 추론통계의 특성을 구분할 수 있다.
```
- 데이터 과학 프로세스
![Image](https://github.com/user-attachments/assets/7f56ee34-5bc9-4155-b351-67f2c2f8d27c)

## 📍 1.2. 머신러닝과 전통적 통계학의 차이

▪️ **머신러닝**: 예측 정확도 향상이 목적. 데이터의 학습과 분류, 예측 자체를 학습하도록 프로그래밍 된 것.  

▪️ **통계학**: 현상 해석이 목적. 모델의 신뢰도를 중시, 단순성을 추구. 확률을 통해 가설을 검증하고, 추정 모델로 데이터를 해석하는 것에 중점.  

▪️ **데이터 과학**: 통계학, 머신러닝, AI 등의 영역을 활용.

## 📍 1.4. 기술 통계와 추론 통계
### ✏️ 1.4.1. 기술 통계
▪️ **기술 통계**: 문자 그대로 주어진 데이터의 특성을 사실에 근거하여 설명 및 묘사하는 것.  
평균, 중앙값, 최빈값 등 여러가지 기준으로 데이터를 설명한다.

▪️ **EDA(탐색적 데이터 분석)**: 데이터를 시각화하거나 통계적으로 요약하여 데이터의 분포, 패턴, 이상치 등 특징을 파악하는 과정.

### ✏️ 1.4.2. 추론 통계
▪️ **추론 통계**: 표본 집단으로부터 모집단의 특성을 추론하는 것이 목적. 

✔️ **기술통계와 추론 통계 통합 프로세스**:   
표본 특성 분석 → 특성의 일반화 여부 판단 → 모집단의 특성으로 추정


# 02. 모집단과 표본추출

```
✅ 학습 목표 :
* 모집단과 표본의 정의와 관계를 설명할 수 있다.
* 편향과 분산의 차이를 설명할 수 있다.
```
## 📍 2.1. 모집단과 표본, 전수조사와 표본조사

![Image](https://github.com/user-attachments/assets/bb16c5d2-2694-4d01-8762-63c30acde9c7)

▪️ **전수조사**: 모집단의 자료 전체를 조사 및 분석하여 정보 추출

▪️ **표본조사**: 추출한 표본으로 모집단의 정보(평균, 표준편차 등)를 추정하고 검정. 모집단의 특성을 최대한 반영할 수 있도록 추출해야 한다.


### ✏️ 2.2. 표본조사를 하는 이유와 데이터 과학 적용 방법
▪️ 전수 데이터를 모두 사용하는 것은 시간 및 비용 측면에서 비효율적이므로, 분석 모델이 완성될 때까지는 표본 데이터를 활용하는 것이 좋다. 데이터 가공 및 변환이 계속해서 일어나므로, 전체 프로세스가 완성되었을 때 전체 데이터를 사용해 성능 확인, 예측 및 분류를 하는 것이 효율적이다.

▪️ 모집단에 대한 정확한 파악이 불가하거나 조사 방법이 특이할 경우에도 표본조사가 사용된다.

▪️ 표지 재포획법: 한 서식지에 서식하는 생물들의 군집의 밀도를 측정하기 위한 방법.  
측정하고자 하는 영역에서, 측정하고자 하는 생물을 포획한 후 표지를 하고, 놓아준 후 재포획하여 다시 포획되는 비율을 이용하여 생물군의 밀도를 측정한다.

## 📍 2.3. 표본추출에서 나타나는 편향의 종류

▪️ **표본 오차**: 모집단의 통계적 특성이 해당 모집단의 하위 집합 또는 표본에서 추정될 때 발생하는 오차

▪️ **비표본 오차**: 표본오차를 제외한 변동, **편향**(표본에서 나타나는 모집단과의 체계적인 차이)으로 인해 발생할 수 있다.
- 표본추출편향: 표본 추출 과정에서 체계적인 경향이 개입되어 모집단에서 편향된 표본만 추출되는 경우
- 가구편향: 모집단의 부분 집단 단위에서 하나의 관측치씩 추출하는 경우 크고 적은 집단이 작고 많은 집단보다 적게 추출되는 경우
- 무응답편향: 설문에 응답하지 않는 사람들과 응답하는 사람들에 체계적인 차이가 있는 경우
- 응답편향: 설문 형식의 문제, 응답자의 심리적 이슈에 의해 표본이 영향을 받는 경우

▪️ 표본 편향은 확률화 등의 방법으로 최소화하거나 없앨 수 있다.

## 📍 2.4. 인지적 편향의 종류
### ✏️ 2.4.1. 확증 편향
▪️ 자신이 본래 믿고 있는 대로 정보를 선택적으로 받아들이고 임의로 판단하는 편향.

### ✏️ 2.4.2. 기준점 편향
▪️ 분석가가 가장 처음에 접하는 정보에 지나치게 매몰되는 편향.

### ✏️ 2.4.3. 선택 지원 편향
▪️ 본인이 의사결정을 내리는 순간 그 선택의 긍정적인 부분에 대해 더 많이 생각하고, 그 결정에 반대되는 증거를 무시하게 되는 편향.

### ✏️ 2.4.4. 분모 편향
▪️ 분수 전체가 아닌 분자에만 집중하여 현황을 왜곡하여 판단하게 되는 편향.

### ✏️ 2.4.5. 생존자 편향
▪️ 소수의 성공 사례를 일반화된 것으로 인식함으로써 나타나는 편향.

## 📍 2.5. 머신러닝 모델 측면의 편향과 분산

![Image](https://github.com/user-attachments/assets/8256aeab-851e-4a93-8c33-1adc69319049)

▪️ 편향과 분산은 트레이드 오프 관계. 

▪️ 모델의 복잡도가 상승할수록, 편향은 감소하지만 분산은 증가한다.

## 📍 2.6. 표본 편향을 최소화하기 위한 표본 추출 방법
**[표본 추출 경우]**  
▪️ 데이터 수집 단계의 표본 추출  
▪️ 빅데이터에서 분석 모델링을 위한 적절한 크기의 표본데이터 추출

**[표본 추출 단계]**  
1️⃣ 모집단 확정  
2️⃣ 표본 프레임 결정  
3️⃣ 표본 추출방법 결정  
4️⃣ 표본크기 결정  
5️⃣ 표본추출  

추출 전, 모집단이 분석 목적에 맞게 세팅되어 있는지 확인 필요.

**[확률 표본추출방법]**

▪️ **단순 임의 추출방법**: 모집단에 대한 사전지식이 없는 경우 유용, 쉽고 빠름.

▪️ **계층적 표본추출방법**: 모든 구성단위에 일련번호 부여 후 일정 간격으로 표본 선택. 모집단 전체에 걸쳐 등간격으로 공평하게 표본 추출, 모집단 배열에 일정한 주기성이 있는 경우 표본의 대표성이 결여될 수 있음.

▪️ **층화 표본추출방법**: 모집단이 특정 기준으로 분류 가능할 때 사용. 모집단에 대한 사전지식과 분류 기준에 대한 충분한 근거 필요. 표본 편중 위험 보완.

▪️ **군집 표본추출방법**: 모집단을 특정 기준으로 분류 후 하나의 소집단을 선택하여 분석. 모집단이 방대한 상황에서 표본추출이 어려울 때 유용, 전체 모집단의 모수를 반영하지 못할 수 있음.

▪️ **복원추출법**: 동일 표본 중복 선택 가능, 표본공간은 독립적으로 변화 없음.

▪️ **비복원추출법**: 표본 추출시 다음 표본드르이 추출 확률에 영향을 미침.  
모집단의 크기가 크지 않거나, 추출하는 표본이 20% 이상으로 많은 경우 복원추출 방식이 편향을 더 줄일 수 있음.

# 03. 변수와 척도
```
✅ 학습 목표 :
* 독립변수, 종속변수의 관계를 파악할 수 있다.
* 척도(변수의 데이터적 속성)의 종류를 설명할 수 있다.
```

## 📍 3.1. 변수의 종류
▪️ 양적변수(이산변수, 연속변수), 질적변수

▪️ 독립변수, 종속변수: 상관관계 있음

▪️ 통제변수, 매개변수, 조절변수

## 📍 3.2. 변수 관계의 종류
▪️ **인과관계**: 독립변수와 종속변수의 기본적 관계. 변수가 다른 변수의 원인이 되는 영향을 미침.

▪️ **상관관계**: 변수 간 관련성이 존재하는 관계. 

▪️ **독립관계**: 상관계수 0

▪️ **의사관계**: 상관성은 있지만, 그 상관성이 다른 변수에 의해 나타난 관계

▪️ **양방향적 인과관계**: 두 변수가 서로 간 인과적 영향을 미치는 관계

▪️ **조절관계**: 독립변수와 종속변수 사이에서 강하고 불확정적인 영향을 미치는 관계

▪️ **매개관계**: 독립변수와 종속변수의 중간에서 매개변수가 개입되어 독립변수의 영향을 종속변수에 전달하는 관계. 시간적 차원이 포함됨.

## 📍 3.3. 척도의 종류
▪️ 질적 척도(명목, 서열), 양적 척도(등간, 비율)

▪️ **명목척도**: 범주 구분 목적, 정보량 가장 적음.

▪️ **서열척도**: 조사대상의 속성 크기를 측정해 대상 간 순서관계를 측정하는 척도. 

▪️ **등간척도**: 순서뿐만 아니라 속성의 상대적 크기 차이도 비교 가능.

▪️ **비율척도**: 순서, 상대적 크기, 절대적 기준을 통한 비율 정보 등. 정보량 가장 많음. 가감승제 가능.

![Image](https://github.com/user-attachments/assets/d2d3a32f-6491-4927-9412-7163e70145af) 

# 04. 데이터의 기술 통계적 측정

```
✅ 학습 목표 :
* 산포도의 의미를 설명하고 측정방법을 나열할 수 있다.
* 정규분포의 왜도값과 첨도값이 얼마인지 답할 수 있다.
```

## 📍 4.1. 중심 성향의 측정
▪️ 중심성향-평균값, 최빈값, 중앙값 등

▪️ **산술평균**: 전체 변숫값을 더한 후 값들의 개수로 나눔.

▪️ **가중평균**: 더 많은 비중을 차지하는 집단에 가중치를 더해 구한 합리적인 평균값.

▪️ **기하평균**: 시간에 따라 비율적으로 변화하는 값의 평균.

▪️ **조화평균**: 시간적으로 변화하는 값의 평균.

▪️ **중앙값**: 내림차순 정렬시 중앙에 위치한 값.

▪️ **최빈값**: 빈도가 가장 높은 값.

## 📍 4.2. 분산과 표준편차
▪️ **분산**: 산술평균과 각 데이터의 편차를 제곱한 것의 평균

## 📍 4.3. 산포도와 범위, 사분위수, 변동계수
▪️ 산포도 측정 방법: 범위, 분산, 표준편차, 사분위수 범위, 변동계수 등.

▪️ **변동계수**: 표준편차를 산술평균으로 나눈 값. 다른 두 자료의 산포도를 비교할 수 있다.

## 📍 4.4. 왜도와 첨도
### ✏️ 4.4.1. 왜도

▪️ 오른쪽으로 긴 꼬리를 가지면 최빈값<중앙값<평균, 왼쪽은 반대.

▪️ 왜도 측정 방법: 피어슨의 비대칭 계수가 가장 간단. 분포가 오른쪽으로 긴 꼬리를 가지면 양수, 반대는 음수를 가진다.

### ✏️ 4.4.2. 첨도

▪️ 첨도 값이 기준보다 크면 양의 첨도(급첨), 작으면 음의 첨도(완첨). 

▪️ 기본적으로 3이 기준값, 편의상 0을 기준으로 하는 경우도 있음

## 📍 4.5. 표준편차의 경험법칙
▪️ **경험법칙**: 일반적인 정규분포에서는 표준편차를 통해 데이터 값들의 범위를 가늠할 수 있음. 표본 크기가 최소 100 이상이 되어야 한다.

    🔹 데이터의 약 68%는 평균으로부터 ±1 표준편차 이내(μ±1σ)에 속한다.  
    🔹 데이터의 약 95%는 평균으로부터 ±2 표준편차 이내(μ±2σ)에 속한다.  
    🔹 데이터의 약 99.7%는 평균으로부터 ±3 표준편차 이내(μ±3σ)에 속한다.

# 05. 확률과 확률변수

```
✅ 학습 목표 :
* 확률변수의 개념과 종류를 설명할 수 있다.
* 심슨의 역설을 설명하고, 발생 원인을 식별하며, 이를 해결하기 위한 방안을 도출할 수 있다.
```

## 📍 5.1. 확률의 기본 개념
▪️ 확률은 표본을 통해 통계치를 산출할 때 생기는 불확실성이 어느정도인지를 이해하기 위해 알아야 한다.

## 📍 5.2. 확률의 종류
▪️ **비조건 확률**(한계확률): 아무런 조건이 없는 상황에서 사건이 일어날 확률. P(A), P(B) 등으로 표현.

▪️ **결합확률**: 표본공간 안에서 일어나는 사건 각각의 조합으로 이루어지는 확률. 교집합. P(A⋂B)로 표현.

▪️ **조건부 확률**: 하나의 사건이 발생했을 때 또 다른 사건이 발생할 확률. P(B|A)로 표현.

## 📍 5.3. 분할과 베이지안 이론
### ✏️ 5.3.1. 분할
▪️ **분할**: 사건들을 모두 합했을 때 전체 사건들을 포괄하되, 중복이 일어나지 않는 사건들의 집합. 

### ✏️ 5.3.2. 베이지안 이론
- P(A): A의 사전 확률
- P(B): B의 사전 확률
- P(B|A): 사건 A(원인)가 전제됐을 때 사건 B(결과)의 조건부확률(우도 확률)
- P(A|B): 사건 B(결과)가 발생했다는 조건에서 사건 A(원인)가 발생했을 확률(사후 확률)

`사전확률 → 새로운 정보(우도 확률) → 베이즈 정리의 응용 → 사후확률`

특정한 사건 A가 발생하면 그 사건의 원인이 되는 사건들의 사전확률을 이용하여 사건 A의 원인이 될 수 있는 사후확률을 알아내는 것.

## 📍 5.4. 확률변수의 개념과 종류
▪️ **확률변수**: 측정값이 변할 수 있는 확률이 주어진 변수. 표본평균, 표본분산 등.

▪️ **이산확률변수**: 변수가 가질 수 있는 값이 실수.

▪️ **연속확률변수**: 연속형. 특정한 값이 아닌, 특정 구간이 나올 수 있는 확률을 구하는 식으로 접근해야 함.


## 📍 5.5. 심슨의 역설
▪️ 데이터의 세부 그룹별로 일정한 추세나 경향성이 나타나지만, 전체적으로 보면 그 추세가 사라지거나 반대 방향의 경향성을 나타내는 현상.

▪️ 데이터를 어떻게 나누고, 결합하고, 가공하는가에 따라 결과가 정반대로 바뀔 수 있음을 경계해야 한다.

-----

# 확인 문제

## 문제 1.

> **🧚Q. 한 대형 병원이 두 명의 외과 의사(A와 B)의 수술 성공률을 비교하려고 한다. 과거 1년간의 데이터를 보면, A 의사의 전체 수술 성공률은 80%, B 의사의 전체 수술 성공률은 90%였다. 이 데이터를 본 병원 경영진은 A 의사의 실력이 B 의사보다 별로라고 판단하여 A 의사의 수술 기회를 줄이는 방향으로 정책을 조정하려 한다.
그러나 일부 의료진은 이 결론에 의문을 제기했다.
그들은 "단순한 전체 성공률이 아니라 더 세부적인 데이터를 분석해야 한다"고 주장했다.**

> **-A 의사의 실력이 실제로 B 의사보다 별로라고 결론짓는 것이 타당한가?   
-그렇지 않다면, 추가로 확인해야 할 정보는 무엇인가?**

<!--심슨의 역설을 이해하였는지 확인하기 위한 문제입니다-->

<!--학습한 개념을 활용하여 자유롭게 설명해 보세요. 구체적인 예시를 들어 설명하면 더욱 좋습니다.-->

```
심슨의 역설을 고려한다면, 단순히 전체 수술 성공률만으로 두 의사의 실력을 판단하는 것이 타당하지 않을 수 있다.
A 의사와 B 의사가 담당한 수술의 난이도, 수술 건수, 수술 대상 환자의 상태 등 다양한 요소를 고려하여 실력을 평가하여야 한다.
```
