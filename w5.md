# 통계학 5주차 정규과제

📌통계학 정규과제는 매주 정해진 분량의 『*데이터 분석가가 반드시 알아야 할 모든 것*』 을 읽고 학습하는 것입니다. 이번 주는 아래의 **Statistics_5th_TIL**에 나열된 분량을 읽고 `학습 목표`에 맞게 공부하시면 됩니다.

아래의 문제를 풀어보며 학습 내용을 점검하세요. 문제를 해결하는 과정에서 개념을 스스로 정리하고, 필요한 경우 추가자료와 교재를 다시 참고하여 보완하는 것이 좋습니다.

5주차는 `2부. 데이터 분석 준비하기`를 읽고 새롭게 배운 내용을 정리해주시면 됩니다.


## Statistics_5th_TIL

### 2부. 데이터 분석 준비하기
### 11.데이터 전처리와 파생변수 생성


## Study Schedule

|주차 | 공부 범위     | 완료 여부 |
|----|----------------|----------|
|1주차| 1부 p.2~56     | ✅      |
|2주차| 1부 p.57~79    | ✅      | 
|3주차| 2부 p.82~120   | ✅      | 
|4주차| 2부 p.121~202  | ✅      | 
|5주차| 2부 p.203~254  | ✅      | 
|6주차| 3부 p.300~356  | 🍽️      | 
|7주차| 3부 p.357~615  | 🍽️      | 

<!-- 여기까진 그대로 둬 주세요-->

# 11.데이터 전처리와 파생변수 생성

```
✅ 학습 목표 :
* 결측값과 이상치를 식별하고 적절한 방법으로 처리할 수 있다.
* 데이터 변환과 가공 기법을 학습하고 활용할 수 있다.
* 모델 성능 향상을 위한 파생 변수를 생성하고 활용할 수 있다.
```


## 📍 11.1. 결측값 처리

▪️ **결측치가 발생하는 특성 분류**

🔹 **완전 무작위 결측**(MCAR: Missing Completely at Random): 결측값이 무작위로 발생  
🔹 **무작위 결측**(MAR: Missing at Random): 다른 변수의 특성에 의해 해당 변수의 결측치가 체계적으로 발생  
🔹 **비무작위 결측**: (NMAR:Missing at Not Random): 결측값들이 해당 변수 자체의 특성을 가짐  

▪️ **결측값 처리 방법**

🔹 **표본 제거 방법**: 결측값이 심하게 많은 변수를 제거하거나 결측값이 포함된 행 제외, 결측값 비율이 10% 미만일 경우.  
🔹 **평균 대치법**: 통계량의 표준오차가 왜곡되어 축소되어 나타나, p값이 부정확해짐. 완전 무작위 결측이 아닌 경우 적절하지 않음.  
🔹 **보간법**(interpolation): 데이터가 시계열적 특성을 가지고 있는 경우.  
🔹 **회귀 대치법**: 해당 변수와 다른 변수 사이의 관계성을 고려하여 결측값 계산, 회귀식 이용. 결측된 변수의 분산을 과소 추정하는 문제가 있어, 인위적으로 회귀식에 확률 오차항을 추가하는 확률적 회귀대치법을 사용하기도 함.  
🔹 **다중 대치법**: 단순대치를 여러 번 수행하여 n개의 가상적 데이터를 생성하여 이들의 평균으로 결측값을 대치하는 방법.  

![Image](https://github.com/user-attachments/assets/7ca970a5-0558-4957-bc1c-21f33945f8b9)

- **대치 단계**: 가능한 대치 값의 분포에서 추출된 서로 다른 값으로 결측치를 처리한 n개의 데이터셋 생성. 일반적으로 몬테카를로(MCMC) 방법이나 연쇄방정식을 통한 다중 대치(MICE)를 사용하여 대치값을 임의로 생성함.
- **분석 단계**: 생성된 각각의 데이터셋을 분석하여 모수의 추정치와 표준오차 계산
- **결합 단계**: 계산된 각 데이터셋의 추정치와 표준오차를 결합하여 최종 결측 대치값 산출

### ✏️ 11.1.1. 결측값 처리 실습

▪️ 결측값의 관측치 제거 시 `dropna()` 함수를 사용

▪️ `dropna(how='all')`: 모든 컬럼의 값이 결측값인 행 제거

▪️ `dropna(how='any')`: 한 컬럼이라도 결측값인 행 제거

▪️ `dropna(subset=['컬럼명'])`: 특정 컬럼이 결측값인 행 제거

▪️ 결측값 시각화(missingno 라이브러리)

![Image](https://github.com/user-attachments/assets/605b668e-eec9-40cb-93ca-1c5d0f43c0c3)

## 📍 11.2. 이상치 처리

▪️ 일반적으로 전체 데이터의 양이 많을수록 이상치가 통곗값에 미치는 영향력이 줄어들어 이상치 제거의 필요성이 낮아짐.

▪️ 실제 분석용 데이터에는 잘못 입력된 데이터 혹은 분석 모델의 정확도를 낮추는 이상치가 많이 존재 -> 이상치 처리 후 모델링하는 것 권장.

▪️ **이상치 처리 방법**

🔹 이상치 제거: 추정치 분산은 감소, 실젯값을 과장하여 편향 발생  
🔹 관측값 변경: 하한 값, 상한 값 결정 후 대체  
🔹 가중치 조정: 이상치의 영향을 감소시키는 가중치 부여  

▪️ **이상치 탐색**

🔹 통계치(평균 또는 중위수) 사용  
🔹 변수의 의미와 도메인 이해  

### ✏️ 11.2.1. 이상치 처리 실습

![Image](https://github.com/user-attachments/assets/4aa81197-9125-4c60-95a8-c5fed2259336)

▪️ **박스플롯**으로 이상치 분포를 쉽게 확인할 수 있다.

🔹 일반적인 박스플롯의 이상치 기준은 IQR 1.5이나, 실무 데이터에서는 분포가 더 넓은 편이므로 IQR 3을 적용할 수도 있다.


## 📍 11.3. 변수 구간화

![Image](https://github.com/user-attachments/assets/5b986be4-8ec3-4080-bb85-af3a2cac92d7)

▪️ **변수 구간화**: 성능 향상 또는 해석의 편리성을 위해 이산형 변수를 범주형 변수로 변환

🔹 비즈니스적 상황에 맞도록 변환함으로써 데이터의 해석이나 예측, 분류 모델을 의도에 맞도록 유도할 수 있음

▪️ 이산 값을 평활화(smoothing)하여 단순 이산 값으로 변환시키기도 함.

🔹 동일 폭 또는 빈도로 구간화하여, 각 구간 안에 속한 데이터 값을 평균, 중앙값, 경곗값 등으로 변환

▪️ 이외에도 클러스터링, 의사결정나무 등의 머신러닝 기법을 사용하기도 함.
🔹 
🔹 

▪️ **WOE 값, IV 값**: 변수값이 효과적으로 구간화되었는지 측정. 종속변수 대비 독립변수가 예측력이 얼마나 강한지를 나타냄.

![Image](https://github.com/user-attachments/assets/d60080c1-be46-48ab-a7c2-da0449a43f7d)

🔹 IV 수치가 높을수록 종속변수의 T/F를 잘 구분할 수 있는 정보량이 많다는 의미. 0.3보다 크면 예측력이 우수한 변수인 것으로 판단함.


## 📍 11.4. 데이터 표준화와 정규화 스케일링

▪️ 표준화

🔹 각 관측치의 값이 전체 평균을 기준으로 어느 정도 떨어져 있는지 나타낼 때 사용  
🔹 평균: 0, 1표준편차 거리: ±1, 2표준편차 거리: ±2로 변환. (Z-score)

▪️ 정규화

🔹 데이터 범위를 0부터 1까지로 변환하여 데이터 분포 조정

▪️ Robust Scaler

🔹 표준화, 정규화 방식의 단점인 이상치에 민감함을 보완한 스케일링 기법(평균 대신 중앙값 사용하여 극단값의 영향을 거의 받지 않음)  
🔹 데이터 중앙값을 0으로 잡고, Q1과 Q3 사분위수와의 IQR 차이를 1이 되도록 하여 이상치의 영향력 최소화

▪️ 표준화나 정규화는 KNN, SVM과 같은 거리 기반 군집 분석에서 필수적임

▪️ 범주화 알고리즘 인공신경망 모델에서도 학습 효율과 분류 성능을 높이기 위해 표준화나 정규화 필수 수행


## 📍 11.5. 모델 성능 향상을 위한 파생 변수 생성

![Image](https://github.com/user-attachments/assets/2ce84f0b-65d6-4ac9-b495-c559a6613c8a)

▪️ 파생변수

🔹 데이터의 특성을 이용하여 분석 효율을 높이는 것이므로 전체 데이터에 대한 파악이 중요, 해당 비즈니스 도메인에 대한 충분한 이해가 수반되어야 함  
🔹 본격적 데이터 분석 모델링 전, 충분한 데이터 탐색 및 시각화 작업 필요  
🔹 모델 성능 향상에 기여할 수 있음

▪️ 파생변수 생성 시 유의점

🔹 기존 변수를 활용하여 만드므로 다중공선성 문제 가능성 높음: 상관분석으로 변수 간 상관성 확인 필요  
🔹 상관성에 따라 파생변수를 그대로 사용할지, 기존 변수를 제외할지, 주성분 분석(PCA)을 사용할지 등을 결정


---

# 확인 문제

## 문제 1. 데이터 전처리

> **🧚 한 금융회사의 대출 데이터에서 `소득` 변수에 결측치가 포함되어 있다. 다음 중 가장 적절한 결측치 처리 방법은 무엇인가?**

> **[보기]   
1️⃣ 결측값이 포함된 행을 모두 제거한다.  
2️⃣ 결측값을 `소득` 변수의 평균값으로 대체한다.  
3️⃣ `연령`과 `직업군`을 독립변수로 사용하여 회귀 모델을 만들어 `소득` 값을 예측한다.  
4️⃣ 결측값을 보간법을 이용해 채운다.**

> **[데이터 특징]**     
    - `소득` 변수는 연속형 변수이다.  
    - 소득과 `연령`, `직업군` 간에 강한 상관관계가 있다.  
    - 데이터셋에서 `소득` 변수의 결측 비율은 15%이다.

```
정답: 3️⃣. 연령, 직업군과의 상관관계가 강하다는 전제 하에서는 회귀 모형이 결측치 처리에 가장 적합하다.

해설
1️⃣: 실제 데이터의 경우 결측값이 있는 행을 모두 제거하기 어려울 정도로 결측값이 많거나, 
결측값 자체가 정보가 되는 경우가 있어 단순 제거 방법은 우선순위로 고려하지 않는다.
해당 문제의 경우 결측 비율이 15%로 비교적 높아 정보 손실이 클 것이다.
2️⃣: 평균값 대체는 쉽고 빠르다는 장점이 있으나, 통계량의 표준오차가 왜곡되어 분산을 과소추정할 수 있다.
4️⃣: 보간법은 시계열 데이터 또는 순서형 데이터에 더 적합하다. 
```

## 문제 2. 데이터 스케일링

> **🧚 머신러닝 모델을 학습하는 과정에서, `연봉(단위: 원)`과 `근속연수(단위: 년)`를 동시에 독립변수로 사용해야 합니다. 연봉과 근속연수를 같은 스케일로 맞추기 위해 어떤 스케일링 기법을 적용하는 것이 더 적절한가요?**

<!--표준화와 정규화의 차이점에 대해 고민해보세요.-->

```
표준화와 정규화 중에서는 표준화가 적절할 것이다. 정규화는 이상치에 더 민감하여 이상치(고연봉자 등)가 전체 스케일을 왜곡하기 쉽다.

단, 각 변수의 분포와 사용 모델을 고려해야 한다.

+) 비대칭 분포이거나 이상치가 있는 것이 확인된 경우: 중앙값 기준&이상치에 민감하지 않은 Robust scaler를 사용하는 것이 적합하다.
```

### 🎉 수고하셨습니다.